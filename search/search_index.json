{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Level10 Tools Runbook \u00b6 Level10 Tools, also known as Product Team , is a web application based on principles from EOS to assist in shaping, planning, coordinating, and developing software products. tech stack Ruby 2.7.2 Ruby on Rails 6 Progressive Web App Stimulus.js (For Front end interactions) Bootstrap (For Css framework) Webpack (For dependency and asset Management) Postgres AWS Elastic Container Service We stick with Rails defaults for testing, what means we use: Minitest Capybara Fixtures Getting Started \u00b6 The recommended development environment utilizes docker-compose to build and execute containers supporting local development. This allows development on any operating system that supports docker and maintains consistent versions of tools and services across local, testing, staging, and production environments. Prerequisites \u00b6 Code editor such as VS Code Tip docker extension for vscode Access to LastPass. Download here and add as a Chrome extension. Create a free account. master.key file required you'll need the master key shared through LastPass touch config/master.key then copy master.key from LastPass to file. docker , note docker-compose should be installed as well. Make (which is installed by default on Mac) Up and running \u00b6 In five easy steps. The development environment uses many services through a virtualized environment. Steps: Clone this repository git clone https://github.com/level10hq/tools Execute the build command make build Initialize the databases make setup Warning If databases already exist this will recreate them Update the databases make migrate Execute the run command make run After successful execution the following containers will be available: web : Ruby on Rails server, http://localhost:3000 webpack : Webpack development server with hot reloading , http://localhost:3335 postgres : Postgres SQL database server, http://localhost:5421 Tip If you want to manage the Postgres database, we provide a command to spin up PGAdmin make pg-admin pgadmin : Adminstrative tool for Postgres, http://locahost:7500 Email: admin@test.com Password: password Tip To find credentials defined for a docker container, consult the docker-compose.yml file. Using docker-compose we bind to the current directy and create volumes for postgres data, Ruby gem cache, and node modules that are not bound locally. level10-tools_postgres_data level10-tools_node_modules level10-tools_container_gems Dropping databases is equivalent to deleting the level10-tools_postgres_data volume and can be done using make drop Note The volumes mentioned are not bound locally so you are free to load the node_modules locally, which we will need to for Cypress testing. In other words, the node_modules directory you see in on the host machine only applies to the host machine. These are ignored through .dockerignore so they will never make it to the container instances. Make Commands \u00b6 make build - Build development container, this will take some time. make run - Start the live-reloading server, postgres database, and web application through docker-compose.yml make setup - Create database(s) if they don't exist make migrate - Migrate database(s) Documentation layout \u00b6 mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-level10-tools-runbook","text":"Level10 Tools, also known as Product Team , is a web application based on principles from EOS to assist in shaping, planning, coordinating, and developing software products. tech stack Ruby 2.7.2 Ruby on Rails 6 Progressive Web App Stimulus.js (For Front end interactions) Bootstrap (For Css framework) Webpack (For dependency and asset Management) Postgres AWS Elastic Container Service We stick with Rails defaults for testing, what means we use: Minitest Capybara Fixtures","title":"Welcome to Level10 Tools Runbook"},{"location":"#getting-started","text":"The recommended development environment utilizes docker-compose to build and execute containers supporting local development. This allows development on any operating system that supports docker and maintains consistent versions of tools and services across local, testing, staging, and production environments.","title":"Getting Started"},{"location":"#prerequisites","text":"Code editor such as VS Code Tip docker extension for vscode Access to LastPass. Download here and add as a Chrome extension. Create a free account. master.key file required you'll need the master key shared through LastPass touch config/master.key then copy master.key from LastPass to file. docker , note docker-compose should be installed as well. Make (which is installed by default on Mac)","title":"Prerequisites"},{"location":"#up-and-running","text":"In five easy steps. The development environment uses many services through a virtualized environment. Steps: Clone this repository git clone https://github.com/level10hq/tools Execute the build command make build Initialize the databases make setup Warning If databases already exist this will recreate them Update the databases make migrate Execute the run command make run After successful execution the following containers will be available: web : Ruby on Rails server, http://localhost:3000 webpack : Webpack development server with hot reloading , http://localhost:3335 postgres : Postgres SQL database server, http://localhost:5421 Tip If you want to manage the Postgres database, we provide a command to spin up PGAdmin make pg-admin pgadmin : Adminstrative tool for Postgres, http://locahost:7500 Email: admin@test.com Password: password Tip To find credentials defined for a docker container, consult the docker-compose.yml file. Using docker-compose we bind to the current directy and create volumes for postgres data, Ruby gem cache, and node modules that are not bound locally. level10-tools_postgres_data level10-tools_node_modules level10-tools_container_gems Dropping databases is equivalent to deleting the level10-tools_postgres_data volume and can be done using make drop Note The volumes mentioned are not bound locally so you are free to load the node_modules locally, which we will need to for Cypress testing. In other words, the node_modules directory you see in on the host machine only applies to the host machine. These are ignored through .dockerignore so they will never make it to the container instances.","title":"Up and running"},{"location":"#make-commands","text":"make build - Build development container, this will take some time. make run - Start the live-reloading server, postgres database, and web application through docker-compose.yml make setup - Create database(s) if they don't exist make migrate - Migrate database(s)","title":"Make Commands"},{"location":"#documentation-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Documentation layout"},{"location":"abbreviations/","text":"","title":"Abbreviations"},{"location":"branching-strategy/","text":"We use Trunk Based Development as our branching strategy. This encourages short lived branches, yet allows experimentation through the use of feature flags . How it works, a practical walkthrough \u00b6 Our trunk is a branch in a single repository that developers on a team focus on for development. In our repositories this is known as the main branch. You have a work item or task that updates code. Create a branch git checkout -b <branchname> . When you are ready to commit, push to origin git push origin <branchname> When you are ready to commit to the main (deployment) branch then create a pull request (PR) through GitHub directly Get the PR reviewed Once approved and necessary checks pass then you as the PR owner can merge to the main branch which will trigger a deployment to https://productteam.level10hq.com","title":"Branching strategy"},{"location":"branching-strategy/#how-it-works-a-practical-walkthrough","text":"Our trunk is a branch in a single repository that developers on a team focus on for development. In our repositories this is known as the main branch. You have a work item or task that updates code. Create a branch git checkout -b <branchname> . When you are ready to commit, push to origin git push origin <branchname> When you are ready to commit to the main (deployment) branch then create a pull request (PR) through GitHub directly Get the PR reviewed Once approved and necessary checks pass then you as the PR owner can merge to the main branch which will trigger a deployment to https://productteam.level10hq.com","title":"How it works, a practical walkthrough"},{"location":"continuous-deployment/","text":"","title":"Continuous deployment"},{"location":"continuous-integration/","text":"We use GitHub Actions as our primary tool for source code automation. Every push to the repository and requests for pulls into the main branch result in a series of Github actions. Deployment to AWS ECS uses Circle CI Deployment to AWS ECS development environment only occurs after successful test execution for commits to the main branch.","title":"Continuous integration"},{"location":"culture/","text":"Engineering Culture \u00b6 We strive to be adaptable with a mindset towards growth. Promoting practices and tools that foster learning and experimentation while building reliable, scalable, delightful software. To that end we focus our efforts on the following practices: Test Driven (reliability) Dev Ops (performance and observability) Experimentation (growth) DORA \u00b6 Source Control Metrics \u00b6","title":"Culture"},{"location":"culture/#engineering-culture","text":"We strive to be adaptable with a mindset towards growth. Promoting practices and tools that foster learning and experimentation while building reliable, scalable, delightful software. To that end we focus our efforts on the following practices: Test Driven (reliability) Dev Ops (performance and observability) Experimentation (growth)","title":"Engineering Culture"},{"location":"culture/#dora","text":"","title":"DORA"},{"location":"culture/#source-control-metrics","text":"","title":"Source Control Metrics"},{"location":"data/","text":"","title":"Data"},{"location":"development/","text":"The Dockerized Development Environment \u00b6 There are many reasons and variations in using a development environment based on docker (and docker-compose). The main reason is to standardize and ease the usage of needed tooling in the development environment. The development lifecycle employs tools for varying functions. To name a few: An interactive development and testing environment such as VSCode The coding frameworks such as Ruby On Rails and Nodejs Compilation and transpilation tools such as webpack dev server Data persistence engines and access such as Postgres and PgAdmin Continuous integration and deployment scripts The documentation tool such as MKDocs Release/deployment automation Although we use docker extensively for instantiating needed services and tools, we install the IDE and other tools such as Cypress natively to get around some sticky scenarios. Recommended native environment \u00b6 VS Code Docker Slack Chrome with LastPass extension git make yarn Chrome DevTools Workspace , this allows writing back to files nodejs cypress (install globally) npm i -g cypress","title":"Development"},{"location":"development/#the-dockerized-development-environment","text":"There are many reasons and variations in using a development environment based on docker (and docker-compose). The main reason is to standardize and ease the usage of needed tooling in the development environment. The development lifecycle employs tools for varying functions. To name a few: An interactive development and testing environment such as VSCode The coding frameworks such as Ruby On Rails and Nodejs Compilation and transpilation tools such as webpack dev server Data persistence engines and access such as Postgres and PgAdmin Continuous integration and deployment scripts The documentation tool such as MKDocs Release/deployment automation Although we use docker extensively for instantiating needed services and tools, we install the IDE and other tools such as Cypress natively to get around some sticky scenarios.","title":"The Dockerized Development Environment"},{"location":"development/#recommended-native-environment","text":"VS Code Docker Slack Chrome with LastPass extension git make yarn Chrome DevTools Workspace , this allows writing back to files nodejs cypress (install globally) npm i -g cypress","title":"Recommended native environment"},{"location":"getting-started/","text":"Getting Started \u00b6 The recommended development environment utilizes docker-compose to build and execute containers supporting local development. This allows development on any operating system that supports docker and maintains consistent versions of tools and services across local, testing, staging, and production environments. Prerequisites \u00b6 Code editor such as VS Code Tip docker extension for vscode Access to LastPass. Download here and add as a Chrome extension. Create a free account. master.key file required you'll need the master key shared through LastPass touch config/master.key then copy master.key from LastPass to file. docker , note docker-compose should be installed as well. Make (which is installed by default on Mac) Up and running \u00b6 In five easy steps. The development environment uses many services through a virtualized environment. Steps: Clone this repository git clone https://github.com/level10hq/tools Execute the build command make build Initialize the databases make setup Warning If databases already exist this will recreate them Update the databases make migrate Execute the run command make run After successful execution the following containers will be available: web : Ruby on Rails server, http://localhost:3000 webpack : Webpack development server with hot reloading , http://localhost:3335 postgres : Postgres SQL database server, http://localhost:5421 Tip If you want to manage the Postgres database, we provide a command to spin up PGAdmin make pg-admin pgadmin : Adminstrative tool for Postgres, http://locahost:7500 Email: admin@test.com Password: password Tip To find credentials defined for a docker container, consult the docker-compose.yml file. Using docker-compose we bind to the current directy and create volumes for postgres data, Ruby gem cache, and node modules that are not bound locally. level10-tools_postgres_data level10-tools_node_modules level10-tools_container_gems Dropping databases is equivalent to deleting the level10-tools_postgres_data volume and can be done using make drop Note The volumes mentioned are not bound locally so you are free to load the node_modules locally, which we will need to for Cypress testing. In other words, the node_modules directory you see in on the host machine only applies to the host machine. These are ignored through .dockerignore so they will never make it to the container instances.","title":"Getting started"},{"location":"getting-started/#getting-started","text":"The recommended development environment utilizes docker-compose to build and execute containers supporting local development. This allows development on any operating system that supports docker and maintains consistent versions of tools and services across local, testing, staging, and production environments.","title":"Getting Started"},{"location":"getting-started/#prerequisites","text":"Code editor such as VS Code Tip docker extension for vscode Access to LastPass. Download here and add as a Chrome extension. Create a free account. master.key file required you'll need the master key shared through LastPass touch config/master.key then copy master.key from LastPass to file. docker , note docker-compose should be installed as well. Make (which is installed by default on Mac)","title":"Prerequisites"},{"location":"getting-started/#up-and-running","text":"In five easy steps. The development environment uses many services through a virtualized environment. Steps: Clone this repository git clone https://github.com/level10hq/tools Execute the build command make build Initialize the databases make setup Warning If databases already exist this will recreate them Update the databases make migrate Execute the run command make run After successful execution the following containers will be available: web : Ruby on Rails server, http://localhost:3000 webpack : Webpack development server with hot reloading , http://localhost:3335 postgres : Postgres SQL database server, http://localhost:5421 Tip If you want to manage the Postgres database, we provide a command to spin up PGAdmin make pg-admin pgadmin : Adminstrative tool for Postgres, http://locahost:7500 Email: admin@test.com Password: password Tip To find credentials defined for a docker container, consult the docker-compose.yml file. Using docker-compose we bind to the current directy and create volumes for postgres data, Ruby gem cache, and node modules that are not bound locally. level10-tools_postgres_data level10-tools_node_modules level10-tools_container_gems Dropping databases is equivalent to deleting the level10-tools_postgres_data volume and can be done using make drop Note The volumes mentioned are not bound locally so you are free to load the node_modules locally, which we will need to for Cypress testing. In other words, the node_modules directory you see in on the host machine only applies to the host machine. These are ignored through .dockerignore so they will never make it to the container instances.","title":"Up and running"},{"location":"testing/","text":"Testing \u00b6 The goal of testing is to verify the quality of the product as well as enable quick development, refactoring, and architectural shifts without compromising quality. Testing Stack \u00b6 We utilize the following toolset for testing our Ruby on Rails application MiniTest : the unit testing library that Rails' built-in testing framework is based on. It provides base classes for test cases, basic assertions like assert_equal and a runner to run tests and report on their success and failre. Capybara : is a Ruby library for full-stack testing of web applications. Capybara allows for selenium-webdriver To communicate with the WebDriver protocol, an HTTP-based protocol for automating browsers We'll step into our dockerized environment through bash to create and execute tests. make bash Note all commands listed below assume you are in the dockerized bash prompt. Testing support through Rails Framework \u00b6 The Rails framework can produce skeleton test code when creating models and controllers. Rails tests can also simulate browser requests allowing verification of an application's response without having to test it through the browser. By default, every Rails application has three environments: development , test , and production . The database for each one of them is configured in config/database.yml . A dedicated test database allows you to set up and interact with test data in isolation. Tests can mangle test data with confidence, that won't touch the data in the development or production databases. Test Directory \u00b6 The application contains a test directory with the following structure. models directory contains tests for models controllers directory contains tests for controllers integration directory contains tests that involve any number of controllers interacting fixtures are a way of organizing test data (sample data). YAML formatted fixtures YAML fixutre format is pre-processes Fixtures API test_helper.rb contains the default configuration for tests. Parallel Tests Rails 6 supports parallel testing through the parallelize class method on TestCase. The default number_of_processors is based on the number of processors on the local machine. So its likely that running tests locally will result in parallel executions. PARALLEL_WORKERS environment variable also always customization. When parallelizing tests, Active Record automatically handles creating a database and loading the schema into the database for each process. The databases will be suffixed with the number corresponding to the worker. For example, if you have 2 workers the tests will create test-database-0 and test-database-1 respectively. Rails automatically wraps any test case in a database transaction that is rolled back after the test completes. Model Testing \u00b6 When using Rails scaffolding to create a model, migration, controller, and views for a new resource it will also create a full test suite following Rails best practices. For example: rails g scaffold Task \\ name:string due_at:datetime done:boolean \\ assigned_to:references discussion:references will create a test stubs in * test/models * test/controllers * system/test as well as a fixture YAML in test/fixtures. Any method defined in the ..._test.rb file starting with test_ (case sensitive) will run automatically when the test case is executed. Rails supplies a test method to ease test creation. To execute the tests: rails test test/models (controllers/system) Note Running rails test will execute all tests in the test directory. Tip Reset test database rails db:test:prepare. rake db:reset RAILS_ENV=test Migrate test database rails db:migrate RAILS_ENV=test System Testing \u00b6 System tests verify user interactions with the application, running tests in either a real or headless browser. System tests use Capybara under the hood. Because system tests use a real browser experience, you can test all of your JavaScript easily from your test suite. These tests are located in the test/system directory and can be generated using rails g system_test ... Tip Using the Rails generator for controller creation will create the test stubs as well. See above. Handling Authentication \u00b6 System and controller testing require authentication. OmniAuth which we use for handling OAuth with Google provides some facilities for mocking the authentication flow for integration tests. Through test mode , all requests to OmniAuth will be short circuited to use the mock authentication hash. OmniAuth . config . test_mode = true A request to /auth/provider will be redirected immediately to /auth/provider/callback . mock_auth configuration allows setting of authentication hashes to be used for mocking. OmniAuth . config . mock_auth [ :google ] = OmniAuth :: AuthHash . new ({ :provider => 'google' , :uid => '123545' # etc. }) Metrics \u00b6 Verification is established through code coverage metrics calulcated through automated test execution. \u00b6","title":"Testing"},{"location":"testing/#testing","text":"The goal of testing is to verify the quality of the product as well as enable quick development, refactoring, and architectural shifts without compromising quality.","title":"Testing"},{"location":"testing/#testing-stack","text":"We utilize the following toolset for testing our Ruby on Rails application MiniTest : the unit testing library that Rails' built-in testing framework is based on. It provides base classes for test cases, basic assertions like assert_equal and a runner to run tests and report on their success and failre. Capybara : is a Ruby library for full-stack testing of web applications. Capybara allows for selenium-webdriver To communicate with the WebDriver protocol, an HTTP-based protocol for automating browsers We'll step into our dockerized environment through bash to create and execute tests. make bash Note all commands listed below assume you are in the dockerized bash prompt.","title":"Testing Stack"},{"location":"testing/#testing-support-through-rails-framework","text":"The Rails framework can produce skeleton test code when creating models and controllers. Rails tests can also simulate browser requests allowing verification of an application's response without having to test it through the browser. By default, every Rails application has three environments: development , test , and production . The database for each one of them is configured in config/database.yml . A dedicated test database allows you to set up and interact with test data in isolation. Tests can mangle test data with confidence, that won't touch the data in the development or production databases.","title":"Testing support through Rails Framework"},{"location":"testing/#test-directory","text":"The application contains a test directory with the following structure. models directory contains tests for models controllers directory contains tests for controllers integration directory contains tests that involve any number of controllers interacting fixtures are a way of organizing test data (sample data). YAML formatted fixtures YAML fixutre format is pre-processes Fixtures API test_helper.rb contains the default configuration for tests. Parallel Tests Rails 6 supports parallel testing through the parallelize class method on TestCase. The default number_of_processors is based on the number of processors on the local machine. So its likely that running tests locally will result in parallel executions. PARALLEL_WORKERS environment variable also always customization. When parallelizing tests, Active Record automatically handles creating a database and loading the schema into the database for each process. The databases will be suffixed with the number corresponding to the worker. For example, if you have 2 workers the tests will create test-database-0 and test-database-1 respectively. Rails automatically wraps any test case in a database transaction that is rolled back after the test completes.","title":"Test Directory"},{"location":"testing/#model-testing","text":"When using Rails scaffolding to create a model, migration, controller, and views for a new resource it will also create a full test suite following Rails best practices. For example: rails g scaffold Task \\ name:string due_at:datetime done:boolean \\ assigned_to:references discussion:references will create a test stubs in * test/models * test/controllers * system/test as well as a fixture YAML in test/fixtures. Any method defined in the ..._test.rb file starting with test_ (case sensitive) will run automatically when the test case is executed. Rails supplies a test method to ease test creation. To execute the tests: rails test test/models (controllers/system) Note Running rails test will execute all tests in the test directory. Tip Reset test database rails db:test:prepare. rake db:reset RAILS_ENV=test Migrate test database rails db:migrate RAILS_ENV=test","title":"Model Testing"},{"location":"testing/#system-testing","text":"System tests verify user interactions with the application, running tests in either a real or headless browser. System tests use Capybara under the hood. Because system tests use a real browser experience, you can test all of your JavaScript easily from your test suite. These tests are located in the test/system directory and can be generated using rails g system_test ... Tip Using the Rails generator for controller creation will create the test stubs as well. See above.","title":"System Testing"},{"location":"testing/#handling-authentication","text":"System and controller testing require authentication. OmniAuth which we use for handling OAuth with Google provides some facilities for mocking the authentication flow for integration tests. Through test mode , all requests to OmniAuth will be short circuited to use the mock authentication hash. OmniAuth . config . test_mode = true A request to /auth/provider will be redirected immediately to /auth/provider/callback . mock_auth configuration allows setting of authentication hashes to be used for mocking. OmniAuth . config . mock_auth [ :google ] = OmniAuth :: AuthHash . new ({ :provider => 'google' , :uid => '123545' # etc. })","title":"Handling Authentication"},{"location":"testing/#metrics","text":"Verification is established through code coverage metrics calulcated through automated test execution.","title":"Metrics"},{"location":"testing/#_1","text":"","title":""}]}